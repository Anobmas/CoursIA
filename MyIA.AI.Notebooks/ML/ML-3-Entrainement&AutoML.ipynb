{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement et AutoML\n",
    "\n",
    "## Dans ce Notebook, vous allez apprendre\n",
    "- Qu'est-ce que l'**entraînement** ?\n",
    "- Introduction aux entraîneurs, quelques-unes de leurs différences, et comment choisir lequel utiliser.\n",
    "- Comment les hyperparamètres impactent les performances de l'entraînement.\n",
    "- Comment utiliser AutoML pour simplifier votre processus d'entraînement.\n",
    "\n",
    "## Qu'est-ce que l'**entraînement** ?\n",
    "Avant de plonger dans le code, parlons d'abord de ce que signifie \"entraîner un modèle\".\n",
    "\n",
    "Dans ML.Net, \"entraîner un modèle\" signifie généralement appeler `model.Fit(X)` dans ML.Net, où `X` est un `IDataView` qui inclut à la fois les caractéristiques et les étiquettes. Alors, que se passe-t-il lorsque vous appelez `Fit` ? En général, `Fit` met à jour les paramètres dans l'entraîneur afin qu'il puisse prédire une étiquette qui soit **proche** de l'étiquette réelle dans `X`, ou en d'autres termes, réduire la distance entre l'étiquette prédite et l'étiquette réelle.\n",
    "\n",
    "En apprentissage automatique, la différence ou la distance entre l'étiquette prédite et l'étiquette réelle est généralement appelée **perte** et vous utilisez différentes mesures de perte en fonction de la tâche. Pour la classification, softmax est une mesure de perte courante. Pour la régression, l'erreur quadratique moyenne (RMSE) est une mesure de perte courante. En général, elles sont toutes des métriques pour quantifier la distance entre l'étiquette prédite et l'étiquette réelle. Dans la plupart des cas, une **perte plus faible signifie un meilleur modèle**. Pour plus d'informations, consultez le [guide des métriques d'évaluation ML.NET](https://docs.microsoft.com/dotnet/machine-learning/resources/metrics).\n",
    "\n",
    "Ainsi, ce que fait `Fit` est d'appliquer un algorithme à vos données pour identifier des motifs et ajuster les paramètres dans cet algorithme pour réduire la perte. Lorsque vous entraînez un modèle, vous voulez réduire sa perte pour rendre la prédiction de ce modèle plus proche de l'étiquette réelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div><strong>Restore sources</strong><ul><li><span>https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json</span></li></ul></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Data.Analysis, 0.21.1</span></li><li><span>Microsoft.ML.AutoML, 0.21.1</span></li><li><span>Plotly.NET.CSharp, 0.0.1</span></li><li><span>Plotly.NET.Interactive, 3.0.2</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\Administrateur.000\\.nuget\\packages\\plotly.net.interactive\\3.0.2\\lib\\netstandard2.1\\Plotly.NET.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\Administrateur.000\\.nuget\\packages\\microsoft.data.analysis\\0.21.1\\interactive-extensions\\dotnet\\Microsoft.Data.Analysis.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\Administrateur.000\\.nuget\\packages\\microsoft.ml.automl\\0.21.1\\interactive-extensions\\dotnet\\Microsoft.ML.AutoML.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading extensions from `C:\\Users\\Administrateur.000\\.nuget\\packages\\skiasharp\\2.88.6\\interactive-extensions\\dotnet\\SkiaSharp.DotNet.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#i \"nuget:https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json\"\n",
    "#r \"nuget: Plotly.NET.Interactive, 3.0.2\"\n",
    "#r \"nuget: Plotly.NET.CSharp, 0.0.1\"\n",
    "#r \"nuget: Microsoft.ML.AutoML\"\n",
    "#r \"nuget: Microsoft.Data.Analysis\"\n",
    "\n",
    "// Import usings.\n",
    "using Microsoft.Data.Analysis;\n",
    "using System;\n",
    "using System.IO;\n",
    "using Microsoft.ML;\n",
    "using Microsoft.ML.AutoML;\n",
    "using Microsoft.ML.Data;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les entraîneurs dans ML.Net\n",
    "ML.NET fournit une variété d'entraîneurs. Vous pouvez en trouver la plupart sous le [StandardTrainersCatalog](https://docs.microsoft.com/dotnet/api/microsoft.ml.standardtrainerscatalog?view=ml-dotnet). Exemples d'entraîneurs : des entraîneurs linéaires comme `SDCA`, `Lbfgs`, `LinearSvm` et des entraîneurs non linéaires basés sur les arbres comme `FastTree`, `RandomForest` et `LightGbm`. En général, les capacités de chaque entraîneur sont différentes. Les modèles non linéaires ont parfois de meilleures performances d'entraînement (perte plus faible) que les modèles linéaires, mais cela ne signifie pas toujours qu'ils sont toujours le meilleur choix. Choisir le bon entraîneur pour construire le meilleur modèle pour vos données nécessite de nombreux essais et erreurs.\n",
    "\n",
    "### Surapprentissage et sous-apprentissage\n",
    "Le surapprentissage et le sous-apprentissage sont les deux problèmes les plus courants que vous rencontrez lors de l'entraînement d'un modèle. Le sous-apprentissage signifie que l'entraîneur sélectionné n'est pas assez performant pour ajuster le jeu de données d'entraînement et résulte généralement en une perte élevée pendant l'entraînement et un score/métrique faible sur le jeu de test. Pour résoudre ce problème, vous devez soit sélectionner un modèle plus puissant, soit effectuer davantage d'ingénierie des fonctionnalités. Le surapprentissage est l'inverse, ce qui se produit lorsque le modèle apprend trop bien les données d'entraînement. Cela résulte généralement en une perte faible pendant l'entraînement mais une perte élevée sur le jeu de test.\n",
    "\n",
    "Une bonne analogie pour ces concepts est l'étude pour un examen. Disons que vous connaissiez à l'avance les questions et les réponses. Après avoir étudié, vous passez l'examen et obtenez un score parfait. Bonne nouvelle ! Cependant, lorsqu'on vous donne à nouveau l'examen avec les questions réarrangées et légèrement reformulées, vous obtenez un score plus bas. Cela suggère que vous avez mémorisé les réponses sans vraiment apprendre les concepts sur lesquels vous étiez évalué. C'est un exemple de surapprentissage. Le sous-apprentissage est l'inverse, où les matériaux d'étude que vous avez reçus ne représentent pas précisément ce sur quoi vous êtes évalué pour l'examen. En conséquence, vous devez deviner les réponses car vous n'avez pas suffisamment de connaissances pour répondre correctement.\n",
    "\n",
    "### Différence entre paramètre et hyper-paramètre\n",
    "En résumé, les paramètres sont internes à un entraîneur et sont mis à jour en fonction du jeu de données d'entraînement pendant le processus d'entraînement (`Fit`). Les hyper-paramètres sont externes à un entraîneur et contrôlent le processus d'entraînement. Par exemple, dans `LightGbm`, le `LearningRate` est un hyper-paramètre que vous pouvez désigner lors de la création et il contrôle les étapes de mise à jour pour le poids des nœuds de l'arbre pendant l'entraînement. Et le poids des nœuds de l'arbre est un paramètre qui est ajusté pendant le processus `Fit`.\n",
    "\n",
    "### Optimisation des hyper-paramètres\n",
    "Choisir le bon entraîneur impacte vos performances finales d'entraînement. Choisir les bons hyper-paramètres a également un impact énorme sur les performances finales de l'entraînement, en particulier pour les entraîneurs basés sur les arbres. Les hyper-paramètres sont importants car ils contrôlent comment les paramètres sont mis à jour. Par exemple, un plus grand `numberOfLeaves` dans `LightGbm` produit un modèle plus grand et permet généralement de s'adapter à un jeu de données plus complexe, mais cela peut avoir un effet contraire sur un petit jeu de données et provoquer un **surapprentissage**. À l'inverse, si le jeu de données est complexe mais que vous définissez un petit `numberOfLeaves`, cela peut nuire à la capacité de `LightGbm` à s'adapter à ce jeu de données et provoquer un **sous-apprentissage**.\n",
    "\n",
    "Le processus de recherche de la meilleure configuration pour votre entraîneur est connu sous le nom d'optimisation des hyper-paramètres (HPO). Comme le processus de choix de votre entraîneur, il implique beaucoup d'essais et d'erreurs. Les capacités intégrées de ML automatisé (AutoML) dans ML.NET simplifient le processus de HPO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"table_638519783573587713\"><thead><tr><th><i>index</i></th><th>X</th><th>y</th></tr></thead><tbody><tr><td><i><div class=\"dni-plaintext\"><pre>0</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-1000</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99997.734</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>1</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.9</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99986.83</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>2</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.8</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99977.32</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>3</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.7</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99969.42</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>4</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.60004</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99962.94</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>5</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.5</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99949.414</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>6</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.4</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99935.94</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>7</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.3</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99930.58</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>8</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.2</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99915.23</pre></div></td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>9</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>-999.10004</pre></div></td><td><div class=\"dni-plaintext\"><pre>-99912.266</pre></div></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var rand = new Random(0);\n",
    "var context =new MLContext(seed: 1);\n",
    "var x = Enumerable.Range(-10000, 10000).Select(_x => _x * 0.1f).ToArray();\n",
    "var y = x.Select(_x => 100 * _x + (rand.NextSingle() - 0.5f) * 10).ToArray();\n",
    "var df = new DataFrame();\n",
    "df[\"X\"] = DataFrameColumn.Create(\"X\", x);\n",
    "df[\"y\"] = DataFrameColumn.Create(\"y\", y);\n",
    "var trainTestSplit = context.Data.TrainTestSplit(df);\n",
    "df.Head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple 1 : Régression linéaire\n",
    "Dans la section ci-dessous, nous allons montrer la différence entre les entraîneurs via une tâche de régression linéaire. Tout d'abord, nous ajustons le jeu de données linéaire avec l'entraîneur linéaire `SDCA`. Ensuite, nous ajustons le jeu de données linéaire avec `LightGbm`, un entraîneur non linéaire basé sur les arbres. Leurs performances sont évaluées par rapport à un jeu de test. Le code ci-dessous :\n",
    "- Crée un jeu de données linéaire et le divise en ensembles d'entraînement et de test\n",
    "- Crée des pipelines d'entraînement utilisant `SDCA` et `LightGbm`\n",
    "- Entraîne `SDCA` et `LightGbm` sur le jeu d'entraînement linéaire, et les évalue sur le jeu de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdca rmse sur trainset: 2,8951204813881493, lgbm rmse sur trainset: 117,9591141671402\n",
      "sdca rmse sur testset: 2,929563459492453, lgbm rmse sur testset: 119,860254032606\n"
     ]
    }
   ],
   "source": [
    "var sdcaPipeline = context.Transforms.Concatenate(\"Features\", \"X\")\n",
    "                            .Append(context.Regression.Trainers.Sdca(\"y\"));\n",
    "\n",
    "var lgbmPipeline = context.Transforms.Concatenate(\"Features\", \"X\")\n",
    "                            .Append(context.Regression.Trainers.LightGbm(\"y\"));\n",
    "\n",
    "var sdcaModel = sdcaPipeline.Fit(trainTestSplit.TrainSet);\n",
    "var lgbmModel = lgbmPipeline.Fit(trainTestSplit.TrainSet);\n",
    "\n",
    "// évaluation sur le jeu d'entraînement\n",
    "var sdcaTrainEval = sdcaModel.Transform(trainTestSplit.TrainSet);\n",
    "var sdcaTrainMetric = context.Regression.Evaluate(sdcaTrainEval, \"y\");\n",
    "\n",
    "var lgbmTrainEval = lgbmModel.Transform(trainTestSplit.TrainSet);\n",
    "var lgbmTrainMetric = context.Regression.Evaluate(lgbmTrainEval, \"y\");\n",
    "\n",
    "Console.WriteLine($\"sdca rmse sur trainset: {sdcaTrainMetric.RootMeanSquaredError}, lgbm rmse sur trainset: {lgbmTrainMetric.RootMeanSquaredError}\");\n",
    "\n",
    "// évaluation sur le jeu de test\n",
    "var sdcaTestEval = sdcaModel.Transform(trainTestSplit.TestSet);\n",
    "var sdcaTestMetric = context.Regression.Evaluate(sdcaTestEval, \"y\");\n",
    "\n",
    "var lgbmTestEval = lgbmModel.Transform(trainTestSplit.TestSet);\n",
    "var lgbmTestMetric = context.Regression.Evaluate(lgbmTestEval, \"y\");\n",
    "Console.WriteLine($\"sdca rmse sur testset: {sdcaTestMetric.RootMeanSquaredError}, lgbm rmse sur testset: {lgbmTestMetric.RootMeanSquaredError}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple 2 : Régression non linéaire sur LightGbm\n",
    "Cet exemple montre l'importance de l'optimisation des hyper-paramètres. Tout d'abord, nous créons un jeu de données non linéaire et deux pipelines. Un pipeline a `LightGbm` avec `numberOfLeaves` défini à `10`, l'autre est défini à `1000`. Les deux pipelines sont entraînés avec le même jeu de données d'entraînement et leurs performances sont évaluées sur le même jeu de test.\n",
    "\n",
    "## Créer un jeu de données non linéaire\n",
    "Le code ci-dessous crée un jeu de données non linéaire avec un résidu aléatoire. Le jeu de données est chargé dans un ensemble d'entraînement et un ensemble de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small lgbm rmse sur testset: 173938,52924678137, large lgbm rmse sur testset: 132927,2510939994\r\n"
     ]
    }
   ],
   "source": [
    "var rand = new Random(0);\n",
    "var context = new MLContext(seed: 1);\n",
    "var x = Enumerable.Range(-10000, 10000).Select(_x => _x * 0.1f).ToArray();\n",
    "var y = x.Select(_x => 100 * _x * _x + (rand.NextSingle() - 0.5f) * 10).ToArray();\n",
    "var df = new DataFrame();\n",
    "df[\"X\"] = DataFrameColumn.Create(\"X\", x);\n",
    "df[\"y\"] = DataFrameColumn.Create(\"y\", y);\n",
    "var trainTestSplit = context.Data.TrainTestSplit(df);\n",
    "df.Head(10);\n",
    "\n",
    "var smallLgbmPipeline = context.Transforms.Concatenate(\"Features\", \"X\")\n",
    "                            .Append(context.Regression.Trainers.LightGbm(\"y\", numberOfLeaves: 10));\n",
    "\n",
    "var largeLgbmPipeline = context.Transforms.Concatenate(\"Features\", \"X\")\n",
    "                            .Append(context.Regression.Trainers.LightGbm(\"y\", numberOfLeaves: 1000));\n",
    "\n",
    "var smallLgbmModel = smallLgbmPipeline.Fit(trainTestSplit.TrainSet);\n",
    "var largeLgbmModel = largeLgbmPipeline.Fit(trainTestSplit.TrainSet);\n",
    "\n",
    "// évaluation sur le jeu de test\n",
    "var smallTestEval = smallLgbmModel.Transform(trainTestSplit.TrainSet);\n",
    "var smallLgbmMetric = context.Regression.Evaluate(smallTestEval, \"y\");\n",
    "\n",
    "var largeLgbmEval = largeLgbmModel.Transform(trainTestSplit.TrainSet);\n",
    "var largeLgbmMetric = context.Regression.Evaluate(largeLgbmEval, \"y\");\n",
    "\n",
    "Console.WriteLine($\"small lgbm rmse sur testset: {smallLgbmMetric.RootMeanSquaredError}, large lgbm rmse sur testset: {largeLgbmMetric.RootMeanSquaredError}\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser AutoML pour simplifier la sélection des entraîneurs et l'optimisation des hyper-paramètres\n",
    "La sélection des entraîneurs et l'optimisation des hyper-paramètres est un processus important avec beaucoup d'essais et d'erreurs. Ce processus peut être automatisé et simplifié en utilisant les capacités intégrées de `AutoMLExperiment`. `AutoMLExperiment` applique les dernières recherches de Microsoft Research pour effectuer une optimisation des hyper-paramètres rapide, précise et complète avec un budget de temps limité.\n",
    "\n",
    "Le code ci-dessous montre comment utiliser `AutoMLExperiment` pour trouver le meilleur entraîneur ainsi que ses meilleurs hyper-paramètres sur le jeu de données non linéaire utilisé dans l'Exemple 2. Tout d'abord, un `SweepableEstimatorPipeline` est créé via `context.Auto().Regression(\"y\")`, qui renvoie les régressions les plus populaires avec leur espace de recherche par défaut dans ML.Net. Ensuite, un `AutoMLExperiment` est créé. Il utilise `RootMeanSquaredError` comme métrique d'optimisation et la validation train-test pour évaluer le score des essais, et utilise `NotebookMonitor` pour présenter le processus d'entraînement. Une fois l'entraînement terminé, il renvoie le meilleur essai comme résultat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><h3>Best Trial</h3><p>Id: 9</p><p>Trainer: FastForestRegression</p><p>Parameters: {\r\n",
       "  &quot;_pipeline_&quot;: {\r\n",
       "    &quot;_SCHEMA_&quot;: &quot;e0 * e2&quot;,\r\n",
       "    &quot;e0&quot;: {},\r\n",
       "    &quot;e2&quot;: {\r\n",
       "      &quot;NumberOfTrees&quot;: 7734,\r\n",
       "      &quot;NumberOfLeaves&quot;: 1031,\r\n",
       "      &quot;FeatureFraction&quot;: 0.8637491,\r\n",
       "      &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "      &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "    }\r\n",
       "  },\r\n",
       "  &quot;_SCHEMA_&quot;: &quot;e0 * e1&quot;,\r\n",
       "  &quot;e0&quot;: {},\r\n",
       "  &quot;e1&quot;: {\r\n",
       "    &quot;NumberOfLeaves&quot;: 4,\r\n",
       "    &quot;MinimumExampleCountPerLeaf&quot;: 20,\r\n",
       "    &quot;NumberOfTrees&quot;: 4,\r\n",
       "    &quot;MaximumBinCountPerFeature&quot;: 255,\r\n",
       "    &quot;FeatureFraction&quot;: 1,\r\n",
       "    &quot;LearningRate&quot;: 0.09999999999999998,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;,\r\n",
       "    &quot;DiskTranspose&quot;: false\r\n",
       "  },\r\n",
       "  &quot;e2&quot;: {\r\n",
       "    &quot;NumberOfTrees&quot;: 4,\r\n",
       "    &quot;NumberOfLeaves&quot;: 4,\r\n",
       "    &quot;FeatureFraction&quot;: 1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  },\r\n",
       "  &quot;e3&quot;: {\r\n",
       "    &quot;NumberOfLeaves&quot;: 4,\r\n",
       "    &quot;MinimumExampleCountPerLeaf&quot;: 20,\r\n",
       "    &quot;LearningRate&quot;: 1,\r\n",
       "    &quot;NumberOfTrees&quot;: 4,\r\n",
       "    &quot;SubsampleFraction&quot;: 1,\r\n",
       "    &quot;MaximumBinCountPerFeature&quot;: 255,\r\n",
       "    &quot;FeatureFraction&quot;: 1,\r\n",
       "    &quot;L1Regularization&quot;: 2E-10,\r\n",
       "    &quot;L2Regularization&quot;: 1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  },\r\n",
       "  &quot;e4&quot;: {\r\n",
       "    &quot;L1Regularization&quot;: 1,\r\n",
       "    &quot;L2Regularization&quot;: 1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  },\r\n",
       "  &quot;e5&quot;: {\r\n",
       "    &quot;L1Regularization&quot;: 1,\r\n",
       "    &quot;L2Regularization&quot;: 0.1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  }\r\n",
       "}</p><h3>Active Trial</h3><p>Id: 12</p><p>Trainer: FastForestRegression</p><p>Parameters: {\r\n",
       "  &quot;_pipeline_&quot;: {\r\n",
       "    &quot;_SCHEMA_&quot;: &quot;e0 * e2&quot;,\r\n",
       "    &quot;e0&quot;: {},\r\n",
       "    &quot;e2&quot;: {\r\n",
       "      &quot;NumberOfTrees&quot;: 9057,\r\n",
       "      &quot;NumberOfLeaves&quot;: 32767,\r\n",
       "      &quot;FeatureFraction&quot;: 0.8683133,\r\n",
       "      &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "      &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "    }\r\n",
       "  },\r\n",
       "  &quot;_SCHEMA_&quot;: &quot;e0 * e1&quot;,\r\n",
       "  &quot;e0&quot;: {},\r\n",
       "  &quot;e1&quot;: {\r\n",
       "    &quot;NumberOfLeaves&quot;: 4,\r\n",
       "    &quot;MinimumExampleCountPerLeaf&quot;: 20,\r\n",
       "    &quot;NumberOfTrees&quot;: 4,\r\n",
       "    &quot;MaximumBinCountPerFeature&quot;: 255,\r\n",
       "    &quot;FeatureFraction&quot;: 1,\r\n",
       "    &quot;LearningRate&quot;: 0.09999999999999998,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;,\r\n",
       "    &quot;DiskTranspose&quot;: false\r\n",
       "  },\r\n",
       "  &quot;e2&quot;: {\r\n",
       "    &quot;NumberOfTrees&quot;: 4,\r\n",
       "    &quot;NumberOfLeaves&quot;: 4,\r\n",
       "    &quot;FeatureFraction&quot;: 1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  },\r\n",
       "  &quot;e3&quot;: {\r\n",
       "    &quot;NumberOfLeaves&quot;: 4,\r\n",
       "    &quot;MinimumExampleCountPerLeaf&quot;: 20,\r\n",
       "    &quot;LearningRate&quot;: 1,\r\n",
       "    &quot;NumberOfTrees&quot;: 4,\r\n",
       "    &quot;SubsampleFraction&quot;: 1,\r\n",
       "    &quot;MaximumBinCountPerFeature&quot;: 255,\r\n",
       "    &quot;FeatureFraction&quot;: 1,\r\n",
       "    &quot;L1Regularization&quot;: 2E-10,\r\n",
       "    &quot;L2Regularization&quot;: 1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  },\r\n",
       "  &quot;e4&quot;: {\r\n",
       "    &quot;L1Regularization&quot;: 1,\r\n",
       "    &quot;L2Regularization&quot;: 1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  },\r\n",
       "  &quot;e5&quot;: {\r\n",
       "    &quot;L1Regularization&quot;: 1,\r\n",
       "    &quot;L2Regularization&quot;: 0.1,\r\n",
       "    &quot;LabelColumnName&quot;: &quot;Label&quot;,\r\n",
       "    &quot;FeatureColumnName&quot;: &quot;Features&quot;\r\n",
       "  }\r\n",
       "}</p></div><div><h3>Plot Metrics over Trials</h3></div>\n",
       "<div>\n",
       "    <div id=\"66f72b6e-dc20-4afa-9b65-d169ec2250fb\"><!-- Plotly chart will be drawn inside this DIV --></div>\r\n",
       "<script type=\"text/javascript\">\r\n",
       "\r\n",
       "            var renderPlotly_66f72b6edc204afa9b65d169ec2250fb = function() {\r\n",
       "            var fsharpPlotlyRequire = requirejs.config({context:'fsharp-plotly',paths:{plotly:'https://cdn.plot.ly/plotly-2.6.3.min'}}) || require;\r\n",
       "            fsharpPlotlyRequire(['plotly'], function(Plotly) {\r\n",
       "\r\n",
       "            var data = [{\"type\":\"scatter\",\"name\":\"Plot Metrics over Trials.\",\"mode\":\"markers\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11],\"y\":[1317273.8291811887,1317273.8291811887,30523762.84646684,1278975.795641825,14290842.290757054,1235892.5787888186,1230484.7147084184,1226593.0457964384,6303500.810775703,1217754.0972468057,3562470.2381989574,17916309.157089632],\"marker\":{},\"line\":{},\"showlegend\":false}];\r\n",
       "            var layout = {\"width\":600,\"height\":600,\"template\":{\"layout\":{\"title\":{\"x\":0.05},\"font\":{\"color\":\"rgba(42, 63, 95, 1.0)\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.0)\",\"plot_bgcolor\":\"rgba(229, 236, 246, 1.0)\",\"autotypenumbers\":\"strict\",\"colorscale\":{\"diverging\":[[0.0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1.0,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}},\"geo\":{\"showland\":true,\"landcolor\":\"rgba(229, 236, 246, 1.0)\",\"showlakes\":true,\"lakecolor\":\"rgba(255, 255, 255, 1.0)\",\"subunitcolor\":\"rgba(255, 255, 255, 1.0)\",\"bgcolor\":\"rgba(255, 255, 255, 1.0)\"},\"mapbox\":{\"style\":\"light\"},\"polar\":{\"bgcolor\":\"rgba(229, 236, 246, 1.0)\",\"radialaxis\":{\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"ticks\":\"\"},\"angularaxis\":{\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"ticks\":\"\",\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"gridwidth\":2.0,\"zerolinecolor\":\"rgba(255, 255, 255, 1.0)\",\"backgroundcolor\":\"rgba(229, 236, 246, 1.0)\",\"showbackground\":true},\"yaxis\":{\"ticks\":\"\",\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"gridwidth\":2.0,\"zerolinecolor\":\"rgba(255, 255, 255, 1.0)\",\"backgroundcolor\":\"rgba(229, 236, 246, 1.0)\",\"showbackground\":true},\"zaxis\":{\"ticks\":\"\",\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"gridwidth\":2.0,\"zerolinecolor\":\"rgba(255, 255, 255, 1.0)\",\"backgroundcolor\":\"rgba(229, 236, 246, 1.0)\",\"showbackground\":true}},\"ternary\":{\"aaxis\":{\"ticks\":\"\",\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\"},\"baxis\":{\"ticks\":\"\",\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\"},\"caxis\":{\"ticks\":\"\",\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\"},\"bgcolor\":\"rgba(229, 236, 246, 1.0)\"},\"xaxis\":{\"title\":{\"standoff\":15},\"ticks\":\"\",\"automargin\":true,\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"zerolinecolor\":\"rgba(255, 255, 255, 1.0)\",\"zerolinewidth\":2.0},\"yaxis\":{\"title\":{\"standoff\":15},\"ticks\":\"\",\"automargin\":true,\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"zerolinecolor\":\"rgba(255, 255, 255, 1.0)\",\"zerolinewidth\":2.0},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"shapedefaults\":{\"line\":{\"color\":\"rgba(42, 63, 95, 1.0)\"}},\"colorway\":[\"rgba(99, 110, 250, 1.0)\",\"rgba(239, 85, 59, 1.0)\",\"rgba(0, 204, 150, 1.0)\",\"rgba(171, 99, 250, 1.0)\",\"rgba(255, 161, 90, 1.0)\",\"rgba(25, 211, 243, 1.0)\",\"rgba(255, 102, 146, 1.0)\",\"rgba(182, 232, 128, 1.0)\",\"rgba(255, 151, 255, 1.0)\",\"rgba(254, 203, 82, 1.0)\"]},\"data\":{\"bar\":[{\"marker\":{\"line\":{\"color\":\"rgba(229, 236, 246, 1.0)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"error_x\":{\"color\":\"rgba(42, 63, 95, 1.0)\"},\"error_y\":{\"color\":\"rgba(42, 63, 95, 1.0)\"}}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgba(229, 236, 246, 1.0)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}}}],\"carpet\":[{\"aaxis\":{\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"endlinecolor\":\"rgba(42, 63, 95, 1.0)\",\"minorgridcolor\":\"rgba(255, 255, 255, 1.0)\",\"startlinecolor\":\"rgba(42, 63, 95, 1.0)\"},\"baxis\":{\"linecolor\":\"rgba(255, 255, 255, 1.0)\",\"gridcolor\":\"rgba(255, 255, 255, 1.0)\",\"endlinecolor\":\"rgba(42, 63, 95, 1.0)\",\"minorgridcolor\":\"rgba(255, 255, 255, 1.0)\",\"startlinecolor\":\"rgba(42, 63, 95, 1.0)\"}}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}}}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"pie\":[{\"automargin\":true}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}},\"line\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"}}}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0.0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgba(235, 240, 248, 1.0)\"},\"line\":{\"color\":\"rgba(255, 255, 255, 1.0)\"}},\"header\":{\"fill\":{\"color\":\"rgba(200, 212, 227, 1.0)\"},\"line\":{\"color\":\"rgba(255, 255, 255, 1.0)\"}}}]}},\"xaxis\":{\"title\":{\"text\":\"Trial\"},\"showgrid\":false},\"yaxis\":{\"title\":{\"text\":\"Metric\"},\"showgrid\":false}};\r\n",
       "            var config = {\"responsive\":true};\r\n",
       "            Plotly.newPlot('66f72b6e-dc20-4afa-9b65-d169ec2250fb', data, layout, config);\r\n",
       "});\r\n",
       "            };\r\n",
       "            if ((typeof(requirejs) !==  typeof(Function)) || (typeof(requirejs.config) !== typeof(Function))) {\r\n",
       "                var script = document.createElement(\"script\");\r\n",
       "                script.setAttribute(\"src\", \"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\");\r\n",
       "                script.onload = function(){\r\n",
       "                    renderPlotly_66f72b6edc204afa9b65d169ec2250fb();\r\n",
       "                };\r\n",
       "                document.getElementsByTagName(\"head\")[0].appendChild(script);\r\n",
       "            }\r\n",
       "            else {\r\n",
       "                renderPlotly_66f72b6edc204afa9b65d169ec2250fb();\r\n",
       "            }\r\n",
       "</script>\r\n",
       "\n",
       "    \n",
       "</div>    \n",
       "<div><h3>All Trials Table</h3></div><table id=\"table_638519786594650631\"><thead><tr><th><i>index</i></th><th>Trial</th><th>Metric</th><th>Trainer</th><th>Parameters</th></tr></thead><tbody><tr><td><i><div class=\"dni-plaintext\"><pre>0</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>0</pre></div></td><td><div class=\"dni-plaintext\"><pre>1317273.9</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>1</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>1</pre></div></td><td><div class=\"dni-plaintext\"><pre>1317273.9</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>2</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>2</pre></div></td><td><div class=\"dni-plaintext\"><pre>30523762</pre></div></td><td>FastTreeRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:254,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>3</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>3</pre></div></td><td><div class=\"dni-plaintext\"><pre>1278975.8</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:7,&quot;NumberOfLeaves&quot;:5,&quot;FeatureFraction&quot;:0.9345126,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>4</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>4</pre></div></td><td><div class=\"dni-plaintext\"><pre>14290842</pre></div></td><td>SdcaRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e5&quot;,&quot;e0&quot;:{},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>5</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>5</pre></div></td><td><div class=\"dni-plaintext\"><pre>1235892.6</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:25,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:0.9210086,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>6</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>6</pre></div></td><td><div class=\"dni-plaintext\"><pre>1230484.8</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:40,&quot;NumberOfLeaves&quot;:15,&quot;FeatureFraction&quot;:0.7609502,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>7</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>7</pre></div></td><td><div class=\"dni-plaintext\"><pre>1226593</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:184,&quot;NumberOfLeaves&quot;:172,&quot;FeatureFraction&quot;:0.65245694,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>8</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>8</pre></div></td><td><div class=\"dni-plaintext\"><pre>6303501</pre></div></td><td>LbfgsPoissonRegressionRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e4&quot;,&quot;e0&quot;:{},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>9</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>9</pre></div></td><td><div class=\"dni-plaintext\"><pre>1217754.1</pre></div></td><td>FastForestRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e2&quot;,&quot;e0&quot;:{},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:7734,&quot;NumberOfLeaves&quot;:1031,&quot;FeatureFraction&quot;:0.8637491,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>10</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>10</pre></div></td><td><div class=\"dni-plaintext\"><pre>3562470.2</pre></div></td><td>LightGbmRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e3&quot;,&quot;e0&quot;:{},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:254,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr><tr><td><i><div class=\"dni-plaintext\"><pre>11</pre></div></i></td><td><div class=\"dni-plaintext\"><pre>11</pre></div></td><td><div class=\"dni-plaintext\"><pre>17916310</pre></div></td><td>FastTreeRegression</td><td>{&quot;_pipeline_&quot;:{&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:8,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:5,&quot;MaximumBinCountPerFeature&quot;:234,&quot;FeatureFraction&quot;:0.99999999,&quot;LearningRate&quot;:0.17308655587408103,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false}},&quot;_SCHEMA_&quot;:&quot;e0 * e1&quot;,&quot;e0&quot;:{},&quot;e1&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;NumberOfTrees&quot;:4,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;LearningRate&quot;:0.09999999999999998,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;,&quot;DiskTranspose&quot;:false},&quot;e2&quot;:{&quot;NumberOfTrees&quot;:4,&quot;NumberOfLeaves&quot;:4,&quot;FeatureFraction&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e3&quot;:{&quot;NumberOfLeaves&quot;:4,&quot;MinimumExampleCountPerLeaf&quot;:20,&quot;LearningRate&quot;:1,&quot;NumberOfTrees&quot;:4,&quot;SubsampleFraction&quot;:1,&quot;MaximumBinCountPerFeature&quot;:255,&quot;FeatureFraction&quot;:1,&quot;L1Regularization&quot;:2E-10,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e4&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;},&quot;e5&quot;:{&quot;L1Regularization&quot;:1,&quot;L2Regularization&quot;:0.1,&quot;LabelColumnName&quot;:&quot;Label&quot;,&quot;FeatureColumnName&quot;:&quot;Features&quot;}}</td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"dni-plaintext\"><pre>1217754.0972468057</pre></div><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Microsoft.Data.Analysis;\n",
    "using System;\n",
    "using System.Linq;\n",
    "using Microsoft.ML;\n",
    "using Microsoft.ML.AutoML;\n",
    "using Microsoft.ML.Data;\n",
    "using Plotly.NET;\n",
    "using Plotly.NET.CSharp;\n",
    "\n",
    "// Définir le contexte ML\n",
    "var context = new MLContext(seed: 1);\n",
    "\n",
    "// Générer les données\n",
    "var x = Enumerable.Range(-10000, 10000).Select(_x => _x * 0.1f).ToArray();\n",
    "var y = x.Select(_x => 100 * _x * _x + (new Random(0).NextDouble() - 0.5) * 10).ToArray();\n",
    "\n",
    "// Convertir 'y' en Single (float)\n",
    "var y_single = y.Select(_y => (float)_y).ToArray();\n",
    "\n",
    "// Créer un DataFrame\n",
    "var df = new DataFrame();\n",
    "df[\"X\"] = DataFrameColumn.Create(\"X\", x);\n",
    "df[\"Label\"] = DataFrameColumn.Create(\"Label\", y_single); // Renommer en 'Label'\n",
    "\n",
    "// Diviser le DataFrame en ensembles d'entraînement et de test\n",
    "var trainTestSplit = context.Data.TrainTestSplit(df);\n",
    "\n",
    "// Définir le pipeline de régression\n",
    "var pipeline = context.Transforms.Concatenate(\"Features\", \"X\")\n",
    "    .Append(context.Auto().Regression(\"Label\"));\n",
    "\n",
    "// Configurer le moniteur de Notebook\n",
    "var monitor = new NotebookMonitor(pipeline);\n",
    "var experiment = context.Auto().CreateExperiment();\n",
    "experiment.SetPipeline(pipeline)\n",
    "        .SetRegressionMetric(RegressionMetric.RootMeanSquaredError)\n",
    "        .SetTrainingTimeInSeconds(30)\n",
    "        .SetDataset(trainTestSplit.TrainSet, trainTestSplit.TestSet)\n",
    "        .SetMonitor(monitor);\n",
    "\n",
    "// Configurer le visualiseur\n",
    "monitor.SetUpdate(monitor.Display());\n",
    "\n",
    "// Exécuter l'expérience\n",
    "var res = await experiment.RunAsync();\n",
    "\n",
    "// Obtenir le modèle\n",
    "var model = res.Model;\n",
    "var eval = model.Transform(trainTestSplit.TestSet);\n",
    "var metric = context.Regression.Evaluate(eval, \"Label\");\n",
    "\n",
    "// Afficher le résultat\n",
    "metric.RootMeanSquaredError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuez à apprendre\n",
    "\n",
    "> [⏩ Module suivant - Évaluation du modèle](./04-Model%20Evaluation.ipynb)  \n",
    "> [⏪ Module précédent - Préparation des données et ingénierie des fonctionnalités](./02-Data%20Preparation%20and%20Feature%20Engineering.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
